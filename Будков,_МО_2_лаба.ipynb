{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YaMUdreC/Ml-and-nn-colab/blob/main/%D0%91%D1%83%D0%B4%D0%BA%D0%BE%D0%B2%2C_%D0%9C%D0%9E_2_%D0%BB%D0%B0%D0%B1%D0%B0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Лабораторная № 2\n",
        "\n",
        "Выполнили: Будков Ярослав, Никиточкина Арина, Помогаев Максим"
      ],
      "metadata": {
        "id": "nRDDtyYa_gzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Импорт библиотек\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import SGDClassifier, SGDRegressor\n",
        "from sklearn.metrics import classification_report, mean_squared_error"
      ],
      "metadata": {
        "id": "R9NMQs0__1Ep"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Загрузка данных и разделение на выборки\n",
        "В этом разделе мы загружаем данные для задачи классификации и регрессии,\n",
        "а также разделяем их на обучающие и тестовые выборки в соотношении 80/20.\n"
      ],
      "metadata": {
        "id": "CfsoBJvcZ4Gs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных для классификации\n",
        "heart_data = pd.read_csv('heart.csv')\n",
        "X_class = heart_data.drop('target', axis=1) # удаляет столбец с именем 'target'\n",
        "y_class = heart_data['target']\n",
        "\n",
        "# Загрузка данных для регрессии\n",
        "ad_data = pd.read_csv('Advertising.csv')\n",
        "X_reg = ad_data.drop('sales', axis=1)\n",
        "y_reg = ad_data['sales']"
      ],
      "metadata": {
        "id": "15TSLePVA3TV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разделение данных на обучающие и тестовые выборки"
      ],
      "metadata": {
        "id": "BYCJi8HuaNs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Классификация\n",
        "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.2, random_state=42)\n",
        "\n",
        "# Регрессия\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "2vC7hNbeB7uh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Построение модели классификации\n",
        "\n",
        "В данном разделе мы настраиваем и обучаем модель SGDClassifier с использованием\n",
        "GridSearchCV.\n",
        "\n",
        "Рассматриваем различные функции потерь (perceptron, hinge, squared_hinge)\n",
        "и методы регуляризации (L1, L2, ElasticNet).\n",
        "\n",
        "Оцениваем качество модели на тестовой выборке, используя метрику Classification Report."
      ],
      "metadata": {
        "id": "btB4IeJtaU5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Классификатор\n",
        "\n",
        "# Словарь, в котором определяются гиперпараметры, которые будут использоваться для поиска оптимальных значений при обучении модели\n",
        "param_grid_class = {\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
        "    'loss': ['perceptron', 'hinge', 'squared_hinge'],\n",
        "}\n",
        "# поиск по сетке (Grid Search) для нахождения наилучших гиперпараметров для модели\n",
        "# max_iter=1000: максимальное количество итераций для обучения.\n",
        "# tol=1e-3: Условие остановки, при котором процесс обучения будет остановлен, если изменение в функции потерь менее 0.001\n",
        "# param_grid_class: Передает ранее определенную сетку параметров для поиска.\n",
        "# cv=5: данные будут разбиты на 5 частей, и модель будет обучаться и оцениваться на каждой из этих частей\n",
        "grid_class = GridSearchCV(SGDClassifier(max_iter=1000, tol=1e-3), param_grid_class, cv=5)\n",
        "\n",
        "\n",
        "# Обучает классификатор с использованием поиска по сетке на тренировочных данных.\n",
        "# X_train_class: Признаки (входные данные), используемые для обучения.\n",
        "# y_train_class: Целевые значения (выходные данные), которые модель должна предсказать.\n",
        "#Этот процесс включает в себя перебор всех комбинаций гиперпараметров из param_grid_class и оценку каждой модели\n",
        "grid_class.fit(X_train_class, y_train_class)\n",
        "\n",
        "# Оценка модели\n",
        "best_class_model = grid_class.best_estimator_ # Сохраняет наилучшую модель\n",
        "y_pred_class = best_class_model.predict(X_test_class) # Использует наилучшую модель для предсказания классов на тестовых данных\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test_class, y_pred_class)) # отчет о качестве классификации"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLDN2c0BC_OJ",
        "outputId": "8c25cd21-2f04-49aa-af07-4d88a27c83a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      1.00      0.64        29\n",
            "           1       0.00      0.00      0.00        32\n",
            "\n",
            "    accuracy                           0.48        61\n",
            "   macro avg       0.24      0.50      0.32        61\n",
            "weighted avg       0.23      0.48      0.31        61\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметр 'penalty'\n",
        "\n",
        "Этот параметр определяет тип регуляризации, который будет применяться к модели. Регуляризация — это техника, используемая для уменьшения переобучения модели путем добавления штрафа к величине весов модели.\n",
        "\n",
        "    l1:\n",
        "        Это L1-регуляризация (также известная как Lasso-регуляризация).\n",
        "        Она добавляет сумму абсолютных значений коэффициентов (весов) к функции потерь.\n",
        "        L1-регуляризация может привести к разреженным решениям, т.е. некоторые коэффициенты могут стать равными нулю, что позволяет автоматически выбирать наиболее важные признаки.\n",
        "\n",
        "    l2:\n",
        "        Это L2-регуляризация (также известная как Ridge-регуляризация).\n",
        "        Она добавляет сумму квадратов коэффициентов к функции потерь.\n",
        "        L2-регуляризация способствует уменьшению величины весов, но в отличие от L1, она не приводит к разреженным решениям. Это значит, что все признаки остаются в модели, но их влияние уменьшается.\n",
        "\n",
        "    elasticnet:\n",
        "        Это комбинация L1 и L2-регуляризаций.\n",
        "        Она позволяет использовать преимущества обеих техник: можно получать как разреженные решения, так и управлять величиной весов.\n",
        "        Elastic Net особенно полезен, когда количество признаков значительно превышает количество наблюдений или когда признаки коррелируют друг с другом.\n",
        "\n",
        "\n",
        "\n",
        "Параметр 'loss'\n",
        "\n",
        "Этот параметр определяет функцию потерь, которая будет использоваться для оптимизации модели. Функция потерь измеряет, насколько хорошо модель предсказывает целевые значения.\n",
        "\n",
        "    'perceptron':\n",
        "        Это функция потерь для перцептрона, простейшего типа линейного классификатора.\n",
        "        Она обновляет веса модели только тогда, когда происходит ошибка в классификации. Сложность этой функции в том, что она не всегда сходится, если данные не линейно разделимы.\n",
        "\n",
        "    'hinge':\n",
        "        Потеря хинжа равна нулю, если предсказанное значение уверенно классифицирует пример, и увеличивается, если предсказание неверное или слишком близко к границе между классами\n",
        "\n",
        "    'squared_hinge':\n",
        "        Это модификация функции потерь хинжа. Она отличается тем, что вместо линейной зависимости наказывает квадратом ошибки, что усиливает наказание за большие ошибки\n",
        "\n",
        "    'squared_error':\n",
        "        Стандартная функция потерь для регрессии, которая измеряет среднее квадратов разностей между предсказанными и истинными значениями.\n",
        "\n",
        "    'huber':\n",
        "        Эта функция потерь сочетает в себе свойства квадратичной ошибки и абсолютной ошибки. Она менее чувствительна к выбросам, чем квадратичная ошибка.\n",
        "\n",
        "    'epsilon_insensitive':\n",
        "        Она игнорирует ошибки, которые находятся в пределах определенного порога\n",
        "\n"
      ],
      "metadata": {
        "id": "4ygmxnUaEXao"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Построение модели регрессии\n",
        "\n",
        "Здесь мы настраиваем и обучаем модель SGDRegressor, используя GridSearchCV.\n",
        "\n",
        "Рассматриваем функции потерь (squared_error, huber, epsilon_insensitive) и\n",
        "методы регуляризации (L1, L2, ElasticNet).\n",
        "\n",
        "Рассчитываем среднеквадратичную ошибку (MSE) на тестовой выборке."
      ],
      "metadata": {
        "id": "PxC-dBH9ade0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Регрессор\n",
        "\n",
        "# Параметры для GridSearchCV\n",
        "param_grid_reg = {\n",
        "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
        "    'loss': ['squared_error', 'huber', 'epsilon_insensitive'],\n",
        "}\n",
        "\n",
        "grid_reg = GridSearchCV(SGDRegressor(max_iter=1000, tol=1e-3), param_grid_reg, cv=5)\n",
        "grid_reg.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "# Оценка модели\n",
        "best_reg_model = grid_reg.best_estimator_\n",
        "y_pred_reg = best_reg_model.predict(X_test_reg)\n",
        "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
        "print(f'Mean Squared Error: {mse}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyZDJ8IGDGlE",
        "outputId": "40ba5852-a5fd-453b-9d37-a83475ba9c36"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error: 5.726730755578482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Регрессор\n",
        "\n",
        "Определение гиперпараметров для поиска\n",
        "\n",
        "param_grid_reg: Словарь, содержащий гиперпараметры для поиска оптимальных значений при обучении модели.\n",
        "  - **penalty**: ['l1', 'l2', 'elasticnet'] — тип регуляризации для борьбы с переобучением.\n",
        "  - **loss**: ['squared_error', 'huber', 'epsilon_insensitive'] — функции потерь для регрессии.\n",
        "\n",
        "Поиск по сетке (Grid Search)\n",
        "\n",
        "GridSearchCV: Используется для перебора всех комбинаций гиперпараметров из **param_grid_reg**.\n",
        "\n",
        "  **SGDRegressor**:\n",
        "  - **max_iter=1000**: Максимальное количество итераций обучения.\n",
        "  - **tol=1e-3**: Условие остановки, при котором обучение завершится, если изменение функции потерь менее 0.001.\n",
        "  - **cv=5**: Кросс-валидация на 5 фолдах.\n",
        "\n"
      ],
      "metadata": {
        "id": "Jb5zQpSx2bb6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Минипакетная оптимизация (Minibatch Optimization)\n",
        "\n",
        "В этом разделе реализуется обучение моделей с использованием минипакетов\n",
        "(minibatches) через метод partial_fit.\n",
        "Этот метод позволяет эффективно\n",
        "обновлять веса модели на ограниченном объеме данных.\n",
        "\n",
        "Сравниваем результаты классификатора и регрессора, обученных методом минипакетов.\n"
      ],
      "metadata": {
        "id": "uucdKQG6amWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#(Бонус) Minibatch Optimization\n",
        "\n",
        "# Minibatch Optimization для классификатора\n",
        "batch_size = 32\n",
        "perceptron_mb = SGDClassifier(loss='hinge')  # Используем hinge как пример\n",
        "\n",
        "for i in range(0, len(X_train_class), batch_size):\n",
        "    X_batch = X_train_class[i:i + batch_size]\n",
        "    y_batch = y_train_class[i:i + batch_size]\n",
        "    perceptron_mb.partial_fit(X_batch, y_batch, classes=np.unique(y_train_class))\n",
        "\n",
        "# Оценка модели\n",
        "y_pred_class_mb = perceptron_mb.predict(X_test_class)\n",
        "print(\"Classification Report (Minibatch):\")\n",
        "print(classification_report(y_test_class, y_pred_class_mb))\n",
        "\n",
        "# Minibatch Optimization для регрессора\n",
        "scaler = StandardScaler()\n",
        "X_train_reg_scaled = scaler.fit_transform(X_train_reg)\n",
        "X_test_reg_scaled = scaler.transform(X_test_reg)\n",
        "\n",
        "regressor_mb = SGDRegressor()\n",
        "\n",
        "for i in range(0, len(X_train_reg_scaled), batch_size):\n",
        "    X_batch = X_train_reg_scaled[i:i + batch_size]\n",
        "    y_batch = y_train_reg[i:i + batch_size]\n",
        "    regressor_mb.partial_fit(X_batch, y_batch)\n",
        "\n",
        "# Оценка модели\n",
        "y_pred_reg_mb = regressor_mb.predict(X_test_reg_scaled)\n",
        "mse_mb = mean_squared_error(y_test_reg, y_pred_reg_mb)\n",
        "print(f'Mean Squared Error (Minibatch): {mse_mb}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFbcNVttDBHA",
        "outputId": "d83cb348-d50b-4bbb-97b7-48c517e4b182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (Minibatch):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.90      0.80        29\n",
            "           1       0.88      0.69      0.77        32\n",
            "\n",
            "    accuracy                           0.79        61\n",
            "   macro avg       0.80      0.79      0.79        61\n",
            "weighted avg       0.80      0.79      0.79        61\n",
            "\n",
            "Mean Squared Error (Minibatch): 70.7494083300835\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier, SGDRegressor\n",
        "from sklearn.metrics import classification_report, mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Minibatch Optimization для классификатора\n",
        "perceptron_mb = SGDClassifier(loss='hinge', max_iter=1, warm_start=True)  # warm_start позволяет сохранять веса\n",
        "\n",
        "for i in range(0, len(X_train_class), batch_size):\n",
        "    X_batch = X_train_class[i:i + batch_size]\n",
        "    y_batch = y_train_class[i:i + batch_size]\n",
        "    perceptron_mb.partial_fit(X_batch, y_batch, classes=np.unique(y_train_class))\n",
        "\n",
        "# Оценка модели\n",
        "y_pred_class_mb = perceptron_mb.predict(X_test_class)\n",
        "print(\"Classification Report (Minibatch):\")\n",
        "print(classification_report(y_test_class, y_pred_class_mb))\n",
        "\n",
        "# Minibatch Optimization для регрессора\n",
        "# Добавим нормализацию данных\n",
        "scaler = StandardScaler()\n",
        "X_train_reg_scaled = scaler.fit_transform(X_train_reg)\n",
        "X_test_reg_scaled = scaler.transform(X_test_reg)\n",
        "\n",
        "regressor_mb = SGDRegressor(max_iter=1, warm_start=True)\n",
        "\n",
        "for i in range(0, len(X_train_reg_scaled), batch_size):\n",
        "    X_batch = X_train_reg_scaled[i:i + batch_size]\n",
        "    y_batch = y_train_reg[i:i + batch_size]\n",
        "    regressor_mb.partial_fit(X_batch, y_batch)\n",
        "\n",
        "# Оценка модели\n",
        "y_pred_reg_mb = regressor_mb.predict(X_test_reg_scaled)\n",
        "mse_mb = mean_squared_error(y_test_reg, y_pred_reg_mb)\n",
        "print(f'Mean Squared Error (Minibatch): {mse_mb}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAu1eQIrVLHR",
        "outputId": "23426eb9-b72a-4148-b8e0-70f7de6f9d25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report (Minibatch):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.97      0.80        29\n",
            "           1       0.95      0.59      0.73        32\n",
            "\n",
            "    accuracy                           0.77        61\n",
            "   macro avg       0.82      0.78      0.77        61\n",
            "weighted avg       0.82      0.77      0.76        61\n",
            "\n",
            "Mean Squared Error (Minibatch): 70.79522734730196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Minibatch Optimization для классификатора\n",
        "- **Minibatch Optimization**: Метод обучения, при котором модель обновляется на основе небольших подмножеств данных (*batch size*).\n",
        "- **batch_size = 32**: Размер мини-пакета для обучения.\n",
        "- **SGDClassifier**:\n",
        "  - **loss='hinge'**: Используется функция потерь \"hinge\" (подходит для задач классификации).\n",
        "\n",
        "Итеративное обучение\n",
        "- Данные разбиваются на мини-пакеты размера **batch_size**.\n",
        "- **partial_fit**:\n",
        "  - Выполняет пошаговое обновление модели на каждом мини-пакете.\n",
        "  - Параметр **classes=np.unique(y_class)** передает все возможные классы для корректного обучения.\n",
        "\n"
      ],
      "metadata": {
        "id": "Nm4xTFI634ku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Вывод\n",
        "\n",
        "В ходе работы были построены модели линейной классификации и регрессии с использованием SGDClassifier и SGDRegressor.\n",
        "Основные этапы:\n",
        "- Загрузку данных и их разделение на обучающую и тестовую выборки.\n",
        "- Настройку гиперпараметров через GridSearchCV для выбора оптимальных функций потерь и регуляризации.\n",
        "- Реализацию минипакетной оптимизации с использованием метода partial_fit.\n",
        "\n",
        "Итоговая оценка показала:\n",
        "- Для классификации были получены лучшие гиперпараметры и достигнуты приемлемые метрики на тестовой выборке.\n",
        "- Для регрессии была рассчитана среднеквадратичная ошибка (MSE), отражающая качество предсказаний.\n",
        "- Минипакетная оптимизация продемонстрировала возможность эффективного обучения на частях данных.\n"
      ],
      "metadata": {
        "id": "a0TF-SjYa0oU"
      }
    }
  ]
}